{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SlkEycpBlCKS"
      },
      "outputs": [],
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import warnings\n",
        "\n",
        "#sklearn specific imports\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import hinge_loss\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_validate, cross_val_predict,GridSearchCV\n",
        "from pprint import pprint\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "#global matplotlib settings\n",
        "mpl.rc('figure',figsize=(8,6))\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Following definition helps us supress some warning messages. (Warning: we are purposefully\n",
        "## supressing the warnings, not a good idea in general!).\n",
        "\n",
        "# Ignore all warnings (like convergence..) by sklearn\n",
        "def warn(*args, **kwargs):\n",
        "  pass\n",
        "warnings.warn = warn"
      ],
      "metadata": {
        "id": "lJjxFcwZlDte"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y= fetch_openml('mnist_784',version=1,return_X_y=True)\n",
        "#it returns Data and label as a pandas dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z2Df0golFpE",
        "outputId": "3e0c4269-07f4-42bf-efd8-e8fde22a6488"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "metadata": {
        "id": "c9q3lLhOlHuq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r8EeNJylO32",
        "outputId": "f5f77995-572b-49f8-d539-d45f0645d5a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the sample at the index 2022.\n",
        "X[2022,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeOwoMMxlTQd",
        "outputId": "0ba10dff-70ca-4f66-e1ef-1e7d600b36e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  48.,  18.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         3.,  71., 149., 223., 242., 230., 223., 153.,  29.,   1.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,  14., 185., 254., 254., 254., 254.,\n",
              "       240., 251., 254., 254., 100.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  64.,\n",
              "       209., 254., 206., 138.,  65.,  65.,  43.,  60., 151., 254., 249.,\n",
              "        65.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0., 240., 254., 254., 108.,   0.,   0.,\n",
              "         0.,   0.,   0.,   6., 155., 254., 137.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        73., 205., 205., 170.,   0.,   0.,   0.,   0.,   0.,   0.,  36.,\n",
              "       245., 206.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0., 239., 254.,  48.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0., 239., 254.,  48.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,  60., 249., 242.,  38.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        20., 198., 254., 109.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,  64., 254., 225.,   6.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   2.,  79., 133.,  60.,  60.,  14.,\n",
              "        84., 224., 254.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         6., 254., 254., 254., 254., 218., 230., 254., 254., 108.,  99.,\n",
              "        99.,  99.,  99., 188., 207., 207., 207.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   6., 254., 176.,  11.,  79.,\n",
              "       254., 254., 237., 227., 227., 227., 227., 253., 254., 141., 119.,\n",
              "        89.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   6., 254., 229., 131., 254., 254., 169.,  29.,   0.,   0.,\n",
              "         0.,   0.,  78.,  81.,  14.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   1., 169., 254., 254.,\n",
              "       254., 175.,  31.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  87., 246., 253., 201.,  27.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57.,\n",
              "        72.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# * What is the label of the sample?\n",
        "y[2022]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N7vQUSYzlnF1",
        "outputId": "64e227f2-1b49-4f7f-d1db-7fabe7d98ba8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is mean value of the sample?\n",
        "X[2022,:].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1VHIEBemiFJ",
        "outputId": "5c54da7c-e82f-4c1d-8b2b-76494fcf31f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.761479591836736"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many zeros are there in the sample?\n",
        "\n",
        "unique, counts = np.unique(X[2022,:], return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WgnlgTymsWd",
        "outputId": "2d8d9d0e-2c98-4acb-e3ab-84e58d010973"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 643,\n",
              " 1.0: 2,\n",
              " 2.0: 1,\n",
              " 3.0: 1,\n",
              " 6.0: 5,\n",
              " 10.0: 2,\n",
              " 11.0: 1,\n",
              " 14.0: 3,\n",
              " 18.0: 1,\n",
              " 20.0: 1,\n",
              " 27.0: 1,\n",
              " 29.0: 2,\n",
              " 31.0: 1,\n",
              " 36.0: 1,\n",
              " 38.0: 1,\n",
              " 43.0: 1,\n",
              " 48.0: 3,\n",
              " 53.0: 1,\n",
              " 57.0: 1,\n",
              " 60.0: 4,\n",
              " 64.0: 2,\n",
              " 65.0: 3,\n",
              " 71.0: 1,\n",
              " 72.0: 1,\n",
              " 73.0: 1,\n",
              " 78.0: 1,\n",
              " 79.0: 2,\n",
              " 81.0: 1,\n",
              " 84.0: 1,\n",
              " 87.0: 1,\n",
              " 89.0: 1,\n",
              " 99.0: 4,\n",
              " 100.0: 1,\n",
              " 108.0: 2,\n",
              " 109.0: 1,\n",
              " 119.0: 1,\n",
              " 131.0: 1,\n",
              " 133.0: 1,\n",
              " 137.0: 1,\n",
              " 138.0: 1,\n",
              " 141.0: 1,\n",
              " 149.0: 1,\n",
              " 151.0: 1,\n",
              " 153.0: 1,\n",
              " 155.0: 1,\n",
              " 169.0: 2,\n",
              " 170.0: 1,\n",
              " 175.0: 1,\n",
              " 176.0: 1,\n",
              " 185.0: 1,\n",
              " 188.0: 1,\n",
              " 198.0: 1,\n",
              " 201.0: 1,\n",
              " 205.0: 2,\n",
              " 206.0: 2,\n",
              " 207.0: 3,\n",
              " 209.0: 1,\n",
              " 218.0: 1,\n",
              " 223.0: 2,\n",
              " 224.0: 1,\n",
              " 225.0: 1,\n",
              " 227.0: 4,\n",
              " 229.0: 1,\n",
              " 230.0: 2,\n",
              " 237.0: 1,\n",
              " 239.0: 2,\n",
              " 240.0: 2,\n",
              " 242.0: 2,\n",
              " 245.0: 1,\n",
              " 246.0: 1,\n",
              " 249.0: 2,\n",
              " 251.0: 1,\n",
              " 253.0: 2,\n",
              " 254.0: 32}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset by taking first 10000 images for training and next 2000 images for testing from the original dataset. Answer the following questions.\n",
        "\n",
        "x_train,x_test,y_train,y_test = X[:10000],X[10000:12000],y[:10000],y[10000:12000]"
      ],
      "metadata": {
        "id": "l3JVjXyDnNt5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many unique classes are there in our train dataset: \n",
        "len(np.unique(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "583bTXXyp5Db",
        "outputId": "4330dbfb-bc08-4af2-e733-d36258183321"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of training samples for the digit 6 are\n",
        "idx = np.where(y_train == '6')\n",
        "len(idx[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Kfq3XKp8Tt",
        "outputId": "d97d3eda-cdf5-4fef-9a7c-a0f6752d383d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1014"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of training samples for the digit 9 are\n",
        "idx = np.where(y_train == '9')\n",
        "len(idx[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9najqB3q0uc",
        "outputId": "7abf0163-a2ab-49ed-80e5-3d6a727bde1f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "978"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many unique classes are there in our test dataset: \n",
        "len(np.unique(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhJYN0bXrFyt",
        "outputId": "dce2e1b3-35aa-447c-f911-e2a700712f8f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Which class has more number of test samples?\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO3M_CG4rLEG",
        "outputId": "65159cb2-8a45-4c8e-ee88-9ac626ce72de"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 205,\n",
              " '1': 224,\n",
              " '2': 185,\n",
              " '3': 196,\n",
              " '4': 204,\n",
              " '5': 185,\n",
              " '6': 194,\n",
              " '7': 209,\n",
              " '8': 183,\n",
              " '9': 215}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all digit-6 (Positive class) and digit-9 (Negative class) images and stack them properly as a single datamatrix.\n",
        "# By convention, keep all digit-6 images from index 0 to i followed by digit-9 images from index i+1 to n (i denotes the end index of digit-6 images)\n",
        "# Similarly, collect the respective labels and store it in a variable (Do sanity check).\n",
        "# Set the label values to 1 for positive classes and -1 for negative classes.\n",
        "\n",
        "idx6_train = np.where(y_train == '6')\n",
        "idx9_train = np.where(y_train == '9')\n",
        "idx6_test = np.where(y_train == '6')\n",
        "idx9_test = np.where(y_train == '9')"
      ],
      "metadata": {
        "id": "gs3OGpfxrVjv"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx = np.concatenate((idx6_train, idx9_train), axis = None)\n",
        "test_idx = np.concatenate((idx6_test, idx9_test), axis = None)"
      ],
      "metadata": {
        "id": "XWe1XOQArxAB"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mod = X[train_idx]\n",
        "X_test_mod = X[test_idx]"
      ],
      "metadata": {
        "id": "cSKx2HXyuS_Q"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(idx6_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS0R7jR1vnIQ",
        "outputId": "2541aab6-e090-4cc2-d72b-a62fae44592d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1014"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(idx9_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfWRSqAEwDF7",
        "outputId": "23bed07f-fda5-4403-cd3a-7a45ffcc796f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "978"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_mod = np.concatenate(((1*np.ones(len(idx6_train[0]))),(-1*np.ones(len(idx9_train[0])))), axis = None)\n",
        "y_test_mod = np.concatenate(((1*np.ones(len(idx6_test[0]))),(-1*np.ones(len(idx9_test[0])))), axis = None)"
      ],
      "metadata": {
        "id": "7bdb1Db-yFMd"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "X_sparse = coo_matrix(X_train_mod)\n",
        "\n",
        "X_s, X_sparse_s, y_s = shuffle(X_train_mod, X_sparse, y_train_mod, random_state=1729)"
      ],
      "metadata": {
        "id": "jugs18ufzD6b"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the first three labels starting from the index 0?. Select from the following options,\n",
        "y_s[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNjWMOkEzWeD",
        "outputId": "990e8eec-03a9-439b-e43b-7c9dca3084c1"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1., -1., -1.])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "clf = Perceptron(random_state = 1729,\n",
        "                 eta0 = 1,\n",
        "                 max_iter = 10,\n",
        "                 shuffle = False,\n",
        "                 fit_intercept = True,\n",
        "                 penalty = None, warm_start= True)\n",
        "clf.fit(X_s, y_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "C4qfIb5D0x4-",
        "outputId": "d5c54f82-84ef-466b-c19f-d0c5b7575d4d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(eta0=1, max_iter=10, random_state=1729, shuffle=False,\n",
              "           warm_start=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(eta0=1, max_iter=10, random_state=1729, shuffle=False,\n",
              "           warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(eta0=1, max_iter=10, random_state=1729, shuffle=False,\n",
              "           warm_start=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.coef_[0,69]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNNd0rDk172i",
        "outputId": "e2e7247a-f63e-40a6-d2f4-db625431221b"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "605.0"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qQdCrfA2VMO",
        "outputId": "994e4d3c-49aa-4df5-8661-fd383265d240"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "for i in range(1,6):\n",
        "  clf = Perceptron(random_state = 1729,\n",
        "                  eta0 = 1,\n",
        "                  max_iter = i,\n",
        "                  shuffle = False,\n",
        "                  fit_intercept = True,\n",
        "                  penalty = None, warm_start= True)\n",
        "  clf.fit(X_s, y_s)\n",
        "  print(clf.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdJuuIbK2nzW",
        "outputId": "0729e557-f31e-4cfe-845a-41091778bb19"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.]\n",
            "[-4.]\n",
            "[-4.]\n",
            "[-6.]\n",
            "[-5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8g1z2fWm4Mqh"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJJEHDCg4egK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}