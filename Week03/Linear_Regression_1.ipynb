{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to Build baseline regression model"
      ],
      "metadata": {
        "id": "m7k0VDWP2Bzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`DummyRegressor` helps in creating baseline for regression"
      ],
      "metadata": {
        "id": "ROCs-D6u2F1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `baseline` is the result of a very basic model/solution. You generally create a baseline and then try to make more complex solutions in order to get a better result. If you achieve a better score than the baseline, it is good."
      ],
      "metadata": {
        "id": "9_n0co2s2e85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About DummyRegressor:\n",
        "\n",
        "It makes prediction based on strategy specified\n",
        "\n",
        "Strategy is based on some statistical property of the training set or user specified value"
      ],
      "metadata": {
        "id": "HaY7dpPK3Of8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "gxoQJlus1y1Z",
        "outputId": "0b72f7d0-c73c-49dd-8fad-811838efa75b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e4ae858a71c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdummy_regr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdummy_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdummy_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdummy_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "dummy_regr = DummyRegressor(strategy = 'mean')\n",
        "dummy_regr.fit(X_train, y_train)\n",
        "dummy_regr.predict(X_test)\n",
        "dummy_regr.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How is Linear Regression model Trained?"
      ],
      "metadata": {
        "id": "m4m3lymWZTZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the object of suitable linear regression estimator using one of the below methods:\n",
        "\n",
        "## 1. Normal Equation\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linear_regression = LinearRegression()\n",
        "\n",
        "\n",
        "## 2. Iterative Optimization\n",
        "from sklearn.linear_model import SGRegressor\n",
        "linear_regressor = SGFRegressor()\n",
        "\n",
        "# Step 2: Call the fit method on linear regression object with training feature matrix and label vector as an argument\n",
        "linear_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "PeRCcPe33Cb2",
        "outputId": "a181aec0-8c25-4eb3-f9ea-8cb8f8d1faae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-28fc6060522e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m## 2. Iterative Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlinear_regressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGFRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'SGRegressor' from 'sklearn.linear_model' (/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGDRegressr Estimator:\n",
        "\n",
        "'''\n",
        "1. use for large sample size > 10K examples\n",
        "2. hyperparameters >> Greater Control over Optimization\n",
        "'''\n",
        "\n",
        "`loss = 'squared error'`\n",
        "\n",
        "`loss = 'huber'` : Used making LR robust over outliers\n",
        "\n",
        "\n",
        "`penalty= 'l1'`\n",
        "`penalty = 'l2'`\n",
        "`penalty = 'elasticnet'`\n",
        "\n",
        "\n",
        "`learning_rate = 'constant'`\n",
        "`learning_rate = 'optimal'`\n",
        "`learning_rate = 'invscaling'`\n",
        "`learning_rate = 'adaptive'`\n",
        "\n",
        "\n",
        "`early_stopping= 'True'`\n",
        "`early_stopping= 'False'`"
      ],
      "metadata": {
        "id": "aA_tx5KHayH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## While instantiating SGD Regressor: seed\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regressor = SGDRegressor(random_state = 42)"
      ],
      "metadata": {
        "id": "Fo-gvv7iawvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## how to perfrom feature scaling for SGD Regressor\n",
        "\n",
        "# SGD is sensitive to feature Scaling\n",
        "# Higly recommended to scale input feature matrix"
      ],
      "metadata": {
        "id": "V6p82JG2cJRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sgd = Pipeline([\n",
        "    ('feature_scaling', StandardScaler()),\n",
        "    ('sgd_regressor', SGDRegressor())\n",
        "    ])\n",
        "\n",
        "sgd.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OCuWeADib9qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scaling is not needed for word frequencies and indicator features as\n",
        "# they have intrinsic scale\n",
        "# feature extraction by PCA should be scaled by some constant c such that the\n",
        "# average L2 norm of training data equals one"
      ],
      "metadata": {
        "id": "STu3fK2qjSCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to shuffle training data after each epoch in SGDregressor"
      ],
      "metadata": {
        "id": "nTBcRFAjkSWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regressor = SGDRegressor(shuffle = True)"
      ],
      "metadata": {
        "id": "XDwR_wTmjMG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use set learning rate in SGDRegressor:\n",
        "\n",
        "learning_rate = 'constant'\n",
        "\n",
        "learining_rate = 'invscaling'\n",
        "\n",
        "learining_rate = 'adaptive'\n",
        "\n",
        "\n",
        "What is default setting?\n",
        "\n",
        "`learning_rate = 'invscaling'` `eta0 = 0.01` and `power_T = 0.25`\n",
        "\n",
        "Learning rate reduces after every iteration. \n",
        "\n",
        "in case of inverse scaling:\n",
        "\n",
        "eta = eta0/pow(t, pow_t)"
      ],
      "metadata": {
        "id": "FG-I6H_9kn9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can make changes in hyperparameter to speed up or slow down the process. IF loss is changing slowly then we need to speed up the learning rate. If oscillations then slow down the learning rate"
      ],
      "metadata": {
        "id": "mM1vJ4rMycY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## How to set constant learning rate\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regression = SGDRegressor(learning_rate = 'constant', eta0 = 1e-2)"
      ],
      "metadata": {
        "id": "1PmsEi6IlEgT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to set adaptive learning rate:\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regressor = SGDRegressor(learning_rate = 'adaptive', eta0 = 1e-2)\n",
        "\n",
        "# The learning rate is kept to initial value as long as training loss decreases\n",
        "# when the stopping criterion is reached the learning rate is divided by 5, and the training loop continues\n"
      ],
      "metadata": {
        "id": "0HKbw7-Ny7rO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to set epochs in #SGDRegressors\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_model = SGDRegressor(max_iter = 100)\n"
      ],
      "metadata": {
        "id": "Ni_2m0kYzOfq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD regressor converges after observing approximately 10^6 trainig samples. thus the reasonalble first guesss for the number of iterations for n sampled training set is \n",
        "max_iter = np.ceil(10^6/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "4jQcOsCQzyj3",
        "outputId": "4568e928-ba77-43df-f781-0a191c1cf629"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a8826714161f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# SGD regressor converges after observing approximately 10^6 trainig samples. thus the reasonalble first guesss for the number of iterations for n sampled training set is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to use set stopping criteria in SGDRegressor\n",
        "\n",
        "# option 1:\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regression = SGDRegressor(loss = 'squared_error',\n",
        "                                 max_iter = 500,\n",
        "                                 tol = le-3,\n",
        "                                 n_iter_no_change = 5)\n",
        "\n",
        "# The SGDRegressor stops when the training loss does not improve(loss > Best_loss= tol) for n_iter_no_change epochs\n",
        "# else after maximum number of iterations max_iter.\n",
        "\n",
        "\n",
        "# Option2:\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regressor = SGDRegressor(loss = 'squared_error',\n",
        "                                early_stopping = True,\n",
        "                                max_iter = 500,\n",
        "                                tol = le-3,\n",
        "                                validation_fraction = 0.2,\n",
        "                                n_iter_no_change = 5)\n",
        "\n",
        "## set validation_fraction percentage records from training set as validation set.\n",
        "# Use score method to obtain validation score\n",
        "\n",
        "## The regressor stops when \n",
        "## The validation score does not improve by at least tol for n_iter_no_change consecutive epcoch\n",
        "## else after maximum number of iterations max_iter\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CVvdCZo80G8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use different loss functions in SGDRegressor?"
      ],
      "metadata": {
        "id": "YMkswltU1wJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set loss parameter: squared_loss or huber"
      ],
      "metadata": {
        "id": "CjjMV6U91zoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## how to use average SGD\n",
        "\n",
        "## Option 1: Averaging across all the updates: average = True\n",
        "\n"
      ],
      "metadata": {
        "id": "DXRiZpi-17Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regression = SGDRegressor(average = 10)"
      ],
      "metadata": {
        "id": "1-XRE5pH2FDa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## How do we initialize SGD with weight vector of the previous run?\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "linear_regression = SGDRegressor(warm_start = True)"
      ],
      "metadata": {
        "id": "FTBQ3Hjk2OJB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to monitor SGD loss iteration after iteration"
      ],
      "metadata": {
        "id": "dMXWDisB2w87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_reg = SGDRegressor(max_iter = 1, tol = np.infty,\n",
        "                       warm_start = True, penalty= None,\n",
        "                       learning_rate = 'constant', eta0 = 0.0005)\n",
        "\n",
        "for epoch in range(1000):\n",
        "  sgd_reg.fit(X_train, y_train) # continues where it left off\n",
        "  y_val_predict = sgd_reg.predict(X_val)\n",
        "  val_error = mean_sqaured_error(y_val, y_val_predict)"
      ],
      "metadata": {
        "id": "Gwb1hHT32m8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_inspection"
      ],
      "metadata": {
        "id": "4lGiVn9Z3zRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how to access the weights of trained model:\n",
        "\n",
        "# The weight vectors are stored in coef_ class\n",
        "\n",
        "linear_regressor.ceof_\n",
        "\n",
        "# intercept\n",
        "linear_regressor.intercept_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BFeoDmLf33RE",
        "outputId": "ca6c8af3-9df6-4f1b-85da-34a2275edd98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4f8dab6cefac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# The weight vectors are stored in coef_ class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlinear_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceof_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# intercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SGDRegressor' object has no attribute 'ceof_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inference:"
      ],
      "metadata": {
        "id": "xyQoVovM4RuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step1: arrange data for prediction in feature matrix of shape or in sparse matrix form\n",
        "# Step 2: Call predict method on linear_regression object with feature matrix as argument"
      ],
      "metadata": {
        "id": "0byIMijv4MAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V29DibZgoZC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation:\n"
      ],
      "metadata": {
        "id": "HPewSDmOoc_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1: Split data into train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)\n",
        "\n",
        "## Step 2: Fit linear regression estimator on training set\n",
        "\n",
        "## Step 3: Calculate training error. aka empirical error\n",
        "\n",
        "## Step 4: Calculate test error. aka generalization error"
      ],
      "metadata": {
        "id": "Sy--zP3DoeUl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to evaluate trained linear regression model:"
      ],
      "metadata": {
        "id": "0jDsfNl2pKIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on eval set with\n",
        "# 1. Feature Matrix\n",
        "# 2. Label vector or matrix (single/multi-output)\n",
        "linear_regression.score(X_test, y_test)\n",
        "\n",
        "## The score returns R2 or coefficient of dertermination\n",
        "\n",
        "## R2 = (1 - u/v)\n",
        "## u: Residual sum of squares: SSE: actual and predicted label \n",
        "## u = (Xw-y)T(Xw-y)\n",
        "## v: Total sum of square\n",
        "## v = (y - ymean)T(y - ymean)\n",
        "\n",
        "\n",
        "## The best possible score is 1.0\n",
        "## A constant model which predicts Expected value [y] would get score of 0.0\n",
        "## The score can be negative (becuase the model can be worse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "N-qDnqWpoiH0",
        "outputId": "6464579c-d73d-4ffd-eacd-204db0f8c5b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e50b627322b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 1. Feature Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 2. Label vector or matrix (single/multi-output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'linear_regression' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics to evaluate performance"
      ],
      "metadata": {
        "id": "4HQBH6UHrlNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "eval_score = mean_absolute_error(y_test, y_predicted)\n",
        "\n",
        "\n",
        "## mean_squarred_error\n",
        "from sklearn.metrics import mean_squarred_error\n",
        "eval_score = mean_squarred_error(y_test, y_predicted)\n",
        "\n",
        "## r2_score: same output as score\n",
        "from sklearn.metrics import r2_score\n",
        "eval_score = r2_score(y_test, y_predicted)\n",
        "\n",
        "## mean_squared_log_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "## We use this for targets with exponential growths like population and sales growth.\n",
        "## Penalizes under-estimation heavier than over-estimation\n",
        "\n",
        "\n",
        "## Mean_absolute_percentage_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "eval_score = mean_absolute_error(y_test, y_predicted)\n",
        "## This is sensitive to outliers\n",
        "\n",
        "\n",
        "## median_absolute_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "eval_score = median_absolute_error(y_test, y_predicted)\n",
        "## Robust to outliers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "FpEQGcUIpaaG",
        "outputId": "94fabff3-fef9-4aeb-f694-3466700fd8a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-35b46dc25d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0meval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## How to evaluate regression model on worst case error?\n",
        "\n",
        "from sklearn.metrics import max_error\n",
        "train_error = max_error(y_train, y_predicted)\n",
        "\n",
        "# can be evaluated on test set in same way\n",
        "\n",
        "## Does not support Multi-Output regression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wArPnK9eth2p",
        "outputId": "ddc25cfc-34a8-470f-f78b-9dbafa0f91c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-edcd1160f25e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmax_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# can be evaluated on test set in same way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Scores and errors\n",
        "\n",
        "## score is a metrics for which higher value is better\n",
        "## error is a metrics for which lower value is better\n"
      ],
      "metadata": {
        "id": "IH7bYkjst1jV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert error metrics to score metrics by adding `neg_` suffix\n",
        "\n",
        "Function | Scoring |\n",
        "---------| --------|\n",
        "metrics.mean_absolute_error|neg_mean__absolute_error|\n",
        "metrics.mean_squared_error| neg_mean_squared_error|\n",
        "metrics.mean_squared_log_error| neg_mean_squared_log_error |\n",
        "metrics.median_absolute_error | neg_median_absolute_error"
      ],
      "metadata": {
        "id": "UdUvf7WmuJyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " ## in case we get comparable performance on train and test with this split\n",
        " ## is this performance guaranteed on other splits too?\n",
        "\n",
        " ### is this set sufficiently large?\n",
        " ##### In case this is small the test error obtained may be unstable and would not reflect the true test error on large test set.\n",
        "\n",
        " ### What is the chance that easiest example were kept aside as test by chance?\n",
        " ##### This if happens would lead to optimistic estimation of true test error\n",
        "\n",
        "\n",
        "### we use cross validation for robust performance\n",
        "#### by repeated splitting and\n",
        "#### providing many training and test errors\n",
        "\n",
        "### This enables us to estimate variability in generalization performance of the model\n",
        "### sklearn implements the following cross validation iterators\n",
        "\n",
        "\n",
        "## sklearn impolements following cross validation iterators\n",
        "\n",
        "KFold\n",
        "RepeatedKfold\n",
        "LeaveOneOut\n",
        "ShuffleSplit\n",
        "\n"
      ],
      "metadata": {
        "id": "0sLhInjOuJL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# how to obtain cross-validation performance measure using KFold"
      ],
      "metadata": {
        "id": "I6l3ASxYuJsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import linear_regression\n",
        "\n",
        "lin_reg = Linear_regression()\n",
        "score = cross_val_score(lin_reg, X,y, cv=5)\n",
        "\n",
        "\n",
        "## uses KFold cross validation iterator that divides training data into 5 folds\n",
        "## In each run, it uses 4 folds for training and 1 for evaluation\n",
        "\n",
        "## Alternate ways of writing the same thing:\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import linear_regression\n",
        "\n",
        "lin_reg = linear_regression()\n",
        "kfold_cv = KFold(n_splits=5, random_state = 42)\n",
        "score = cross_val_score(lin_reg, X,y, cv= kfold_cv)\n",
        "\n",
        "## LeaveOneOut: How to use this iterator\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import linear_regression\n",
        "\n",
        "lin_reg = linear_regression()\n",
        "loocv = LeaveOneOut()\n",
        "score = cross_val_score(lin_reg, X,y, cv=loocv)\n",
        "\n",
        "## which is same as :\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import linear_regression\n",
        "\n",
        "lin_reg = linear_regression()\n",
        "n = X.shape[0]\n",
        "kfold_cv = KFold(n_splits = n)\n",
        "score = cross_val_score(lin_reg, X,y, cv=kfold_cv)\n",
        "\n",
        "\n",
        "\n",
        "# shuffle split\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.linear_model import linear_regression\n",
        "\n",
        "lin_reg = linear_regression()\n",
        "shuffle_split = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 42)\n",
        "score = cross_val_score(lin_reg, X,y, cv= shuffle_split)\n",
        "\n",
        "## It is also called as random permutation based cross validation strategy\n",
        "## It generates user defined number of train and test split\n",
        "## It is robust to class distribution\n",
        "\n",
        "## In each iteration it shuffles the order of data samples and then splits in training and test.\n",
        "\n",
        "\n",
        "## Specify performance measure in cross_val_Score\n",
        "\n",
        "score = cross_val_score(lin_reg, X, y, cv= shuffle_split, scoring = 'neg_mean_absolute_error')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "lq0mj7dax0bg",
        "outputId": "fe2659cd-c283-4c16-96cb-4b49d24e87c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b1f364bbc2c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlin_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'linear_regression' from 'sklearn.linear_model' (/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## How to obtain test scores from different folds?\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "cv = ShuffleSplit(n_splits= 40, test_size = 0.3, random_state = 0)\n",
        "cv_results = cross_validate(regressor, data, target, cv=cv, scoring = 'neg_mean_absolute_error')\n",
        "\n",
        "## The results are stored in python dictioanry\n",
        "\n",
        "## Fit time\n",
        "## score_time\n",
        "## test_score\n",
        "## estimator\n",
        "## train_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "aSPbNBft0YlU",
        "outputId": "0cae9b6d-c537-4314-f2bd-5ac58c003907"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-672922f18856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'regressor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = ShuffleSplit(n_splits= 40, test_size = 0.3, random_state = 0)\n",
        "cv_results = cross_validate(regressor, data, target, \n",
        "                            cv=cv, scoring = 'neg_mean_absolute_error'\n",
        "                            return_train_score = True,\n",
        "                            return_estimator = True)\n",
        "# The estimators can be access through the estimators key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "OYFxpq8b1kus",
        "outputId": "e8b1f383-def1-4152-f7d0-6f38218736df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-71d8da37e140>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    return_train_score = True,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple metrics:\n",
        "\n",
        "cv_results = cross_validate(regressor, data, target, \n",
        "                            cv=cv, scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error'],\n",
        "                            return_train_score = True,\n",
        "                            return_estimator = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "5UkJFJGy-rc_",
        "outputId": "7de67e86-32f9-46f2-a349-7420a46fa849"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f6997140f686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# multiple metrics:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m cv_results = cross_validate(regressor, data, target, \n\u001b[0m\u001b[1;32m      4\u001b[0m                             \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mreturn_train_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'regressor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to study the effect of #samples on training and test errors?\n",
        "\n",
        "## Step 1: Instantiate the object of learning_curve class with estimator, training data, size, cv strategy and scoring scheme as arguments.\n",
        "\n",
        "from sklearn.model_selection import learning\n",
        "\n",
        "results = learning_curve(lin_reg, X_train, y_train, train_sizes = train_sizes,\n",
        "                         cv=cv, scoring = 'neg_mean_absolute_error')\n",
        "train_size, train_scores, test_scores = results[:3]\n",
        "\n",
        "# convert the scores into errors \n",
        "train_errors , test_errors = -train_scores, -test_scores\n",
        "\n",
        "## Step 2: Plot the training and test scores as function of size of training sets. \n",
        "## make assessment about the model fitment: under/overfitting\n",
        "\n"
      ],
      "metadata": {
        "id": "7wgu31B6_B6z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for underfitting or overfitting:\n",
        "\n",
        "## Step 1: Fit linear model with different number of features\n",
        "\n",
        "## step 2: For each model obtain training and test errors\n",
        "\n",
        "## Step 3: plot the features vs error graph one each for training and test errors\n",
        "\n",
        "## step 4: examine the graphs to detect under/overfitting\n"
      ],
      "metadata": {
        "id": "AlhMoBY8_T2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}