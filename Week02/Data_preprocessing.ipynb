{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The real world training data is not clean and has many issues: NaN values, or non-numeric attributes etc..\n",
        "\n",
        "So, to preprocess this kind of data- Sklearn provides rich set of `transformers`\n",
        "\n",
        "sklearn provides `pipeline` for making it easier to chain the multiple transformers together and apply them uniformly across train, evaluation and test set"
      ],
      "metadata": {
        "id": "9T_1zxP7Mljz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Typical Problems:\n",
        "  1. Missing values in features\n",
        "  2. No same scale\n",
        "  3. Categorical attributes needs some sensible numerical scale\n",
        "  4. Too many features>> reduce them\n",
        "  5. Extract features from non-numerical data like images, or text etcc "
      ],
      "metadata": {
        "id": "xUxNobmjNQ0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sklearn library:\n",
        "\n",
        "  1. Data Cleaning: `sklearn.preprocessing`- standardization, missing value imputation etc.\n",
        "  2. Feature Extraction: `sklearn.feature_extraction` \n",
        "  3. Feature reduction: `sklearn.decomposition.pca`\n",
        "  4. Feature Expansion: `sklearn.kernel_approximation`"
      ],
      "metadata": {
        "id": "N_FfBSeMN5vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Methods:\n",
        "1. `fit()`: learns model parameters from training set\n",
        "2. `transform()`: applies learnt transformation to new data\n",
        "3. `fit_transform()`: perfroms the function of both `fit` and `transform` and is more convenient and efficient to use."
      ],
      "metadata": {
        "id": "sLe2-zlwOvdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Feature Extraction"
      ],
      "metadata": {
        "id": "68AIlbe-PcMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sklearn.feature_extraction` has useful APIs to extract features from data:\n",
        "\n",
        "  `dictVectorizer`|`FeatureHasher`|\n",
        "  ----------------|--------------|\n",
        "  Converts list of mappings of faturename and value into a matrix | High-Speed, low memory vectorizer that uses feature hashing technique\n",
        "Builds `hash table` of features | It applies `hash function` to the features to determine their column index in sample matrices directly\n",
        "| The hasher does not remember what input feature looked like and thus has `no inverse_transform` method.\n",
        "| Output of this transformer is `scipy.sparse` matrix"
      ],
      "metadata": {
        "id": "L5bju9mYPiLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictVectorizer illustration\n",
        "\n",
        "data = [{'age':4, 'height':96},{'age':5,'height':101}]\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "df = DictVectorizer(sparse = False)\n",
        "df.fit_transform(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jitQUO8NPbPq",
        "outputId": "a9cce6db-b22a-4449-9359-352ad91c095d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  4.,  96.],\n",
              "       [  5., 101.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction from Images and Texts"
      ],
      "metadata": {
        "id": "JKqX07vyTr4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `sklearn.feature_extraction.image.*` class"
      ],
      "metadata": {
        "id": "76gHfzQATwqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `sklearn.feature_extraction.text.*` class"
      ],
      "metadata": {
        "id": "B7TJY_LDT2zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Cleaning Data"
      ],
      "metadata": {
        "id": "kaY6fRznURZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Values:\n",
        "\n",
        "Missing values occur due to error in data capture\n"
      ],
      "metadata": {
        "id": "Eywpmo_qUVs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `sklearn.impute`\n",
        "\n",
        "`MissingIndicator` that provides indications for missing values\n",
        "\n",
        "`SimpleImputer`|`KNNImputer`\n",
        "---|---\n",
        "Fills the missing value with: `mean`, `median`, `most_frequent`, or `constant` | uses K-nearest neighbour approach to fill the missing value\n",
        "| Value filled is `mean` of n_neighbors\n",
        "| The nearest neighbours are decided based on eucledian distance\n"
      ],
      "metadata": {
        "id": "cECM9U4iUk2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# this is just for illustration purpose of simple imputer\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "si = SimpleImputer(strategy ='mean')\n",
        "si.fit_transform(data)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# this is illustration for Knn imputer\n",
        "\n",
        "knni = KNNImputer(n_neighbours = 2, weights = 'uniform')\n",
        "knni.fit_transform(data)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XAHR8sDKWI8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Missing Indicator`"
      ],
      "metadata": {
        "id": "FJYKtGj9Ze-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Return Binary Matrix. True when the value is missing"
      ],
      "metadata": {
        "id": "5U8Z3sWcZoUk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dd5u1RthMh5L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SimpleImputer Strategies:\n",
        "\n",
        "1. `mean`, then replace missing values using the mean along each column. Can only be used with numeric data.\n",
        "2. `median`, then replace missing values using the median along each column. Can only be used with numeric data\n",
        "3. `most_frequent`, then replace missing using the most frequent value along each column. Can be used with strings or numeric data. If there is more than one such value, only the smallest is returned.\n",
        "4. `constant`, then replace missing values with fill_value. Can be used with strings or numeric data."
      ],
      "metadata": {
        "id": "Gdsjg3cEah1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Example\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp = SimpleImputer ( missing_values=np.nan , strategy='median')\n",
        "X = [ [ 4 , 1 ] , [ np . nan , 5 ] , [ 8 , 0 ] ]\n",
        "imp.fit_transform (X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HrOWOlNRQyO",
        "outputId": "0ace9b63-b3e9-43aa-93fe-a51d4f9d82c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4., 1.],\n",
              "       [6., 5.],\n",
              "       [8., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_LRG6BFbPKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}